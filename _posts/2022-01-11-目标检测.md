---
title: Object Detection
date: 2022-01-11 15:47:18
description: none
comments: true
categories:
- Object-Detection
tags:
- Design-of-Graduate
---

ps:输入---再回车可以唤起纯文本格式

# 目标检测

## 目标检测的基本步骤

- 分类
  - 将图像结构化为某一类别的信息，再用预先定好的string或实例ID来描述图片。类似机器学习中使用不同的分类器进行多分类。
- 检测
  - 如果说分类是对整张图片的内容描述，则检测是对该图片的具体object进行分离，同时确定该object的坐标和类别，它的输出通常是一个列表。
- 分割
  - 通常分为semantic segmentation和instance segmentation
  - 前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分；后者是表述目标的轮廓，它是对图像的像素级描述。

![img](https://pic4.zhimg.com/80/v2-33292ce9f50b773d85ce7dedaa73e7a3_720w.jpg)

## 检测方法

**2-stage检测模型**：

指的是的对图像的两阶段处理，也称为基于区域（region-based）方法

- R-CNN

  ![img](https://pic2.zhimg.com/80/v2-ec320f9a52d0d5630be4a8fc9ea93c61_720w.jpg)

  1. 基于图片提出若干可能包含物体的区域，多称为图片局部裁剪(Region Proposal)，之前使用的是Selective Search算法
  2. 在这些区域上运行分类网络AlexNet(当时表现最好的分类网络)到每个区域内物体的类别。

  **Conclusion**：

  R-CNN将检测任务转化为区域的分类任务，但模型本身需要训练三个不同的模型：Proposal，Classification，Regression。且重复计算多可能导致性能问题。

- Fast R-CNN

  ![img](https://pic4.zhimg.com/80/v2-597bf75a922c054ca038fe4c2fc9655f_720w.jpg)

  与R-CNN相对的，该算法先将图片整体经过基础网络运行后再传入R-CNN子网络，以达到共享运算的目的。

- Faster R-CNN

  ![img](https://pic4.zhimg.com/80/v2-35ce8d4e9f9d2c8493f6ca2f894c508f_720w.jpg)

  该算法提出RPN网络取代Selective Search算法是检测任务可以由神经网络端到端完成。精度方面可以达到State of the Art(SOTA)

  **Conclusion**：

  用RPN网络完成检测任务的“深度化”，使用了滑动窗口生成anchor box 的思想在YOLO v2中也有应用。它奠定了“RPN+RCNN”的两阶段方法元结构。

**1-stage 检测模型**

- YOLO

  它算是单阶段方法的开山之作。将检测任务表述成统一的、端到端的回归问题，只**处理一次图片**便可同时得到位置和分类。

  - Features：
    - fast
    - global handle to make less mistake
    - 泛化性能好，应用场景广泛

  ![img](https://pic3.zhimg.com/80/v2-7eeffb8bd247c714f7b5f381b774145a_720w.jpg)

  - 流程：

    - 准备数据：将图片缩放，划分为等分网格，每个网格按Ground Truth（标注数据）的IoU（Intersection over Union）分配所要预测的样本。

      ![img](https://pic2.zhimg.com/80/v2-316f0ffd2d0b0fed3c206bd7616e9edd_720w.jpg)

    - 卷积网络：每个网格对每个类别预测一个条件概率值，并在网格基础上生成B个box(即框)，每个box预测五个回归之，其中四个表征位置，第五个表征box含有物体(不是指某一类物体)的概率和位置的准确程度(用IoU表示)。

      ![img](https://pic3.zhimg.com/80/v2-e3b665a096db8032879742d1c4ba1b5e_720w.jpg)

      等式左边第一项由网格预测，后两项由每个box预测，以条件概率得到每个box含有不同类别物体的分数。因而卷积网络共输出预测值个数为S×S×(B×5+C)，S为网格数，B为每个网格生成box个数，C为类别数。

    - 后处理：使用NMS过滤的到最后预测框(Non-Maximum Suppression，非极大抑制)

  - Defects：

    划分网格较为粗糙，每个网格生成的box个数限制了对小尺度物体和相近物体的检测。

  - 损失函数设计

    ![img](https://pic1.zhimg.com/80/v2-d3de934214afa4a5790463f7f23f2e38_720w.jpg)

    

- SSD(Single Shot Multibox Detector)

  相对YOLO的特点：

  - 多尺度feature map：基于VGG不同卷积段，输出feature map到回归器。提升小物体的检测精度
  - 更多anchor box，每个网格点生成不同大小和长宽比例的box，将类别预测概率基于box预测，得到的输出值个数为(C+4)×k×m×n，其中C为类别数，k为box个数，m×n为feature map的大小。